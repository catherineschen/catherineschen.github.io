---
title:          "MechIR: A Mechanistic Interpretability Framework for Information Retrieval"
date:           2025-04-06 00:00:00 +0800
selected:       true
pub:            "ECIR"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"

abstract: >-
  Mechanistic interpretability is an emerging diagnostic approach for neural models that has gained traction in broader natural language processing domains. This paradigm aims to provide attribution to components of neural systems where causal relationships between hidden layers and output were previously uninterpretable. As the use of neural models in IR for retrieval and evaluation becomes ubiquitous, we need to ensure that we can interpret why a model produces a given output for both transparency and the betterment of systems. This work comprises a flexible framework for diagnostic analysis and intervention within these highly parametric neural systems specifically tailored for IR tasks and architectures. In providing such a framework, we look to facilitate further research in interpretable IR with a broader scope for practical interventions derived from mechanistic interpretability. We provide preliminary analysis and look to demonstrate our framework through an axiomatic lens to show its applications and ease of use for those IR practitioners inexperienced in this emerging paradigm.
# cover:          /assets/images/covers/cover3.jpg
authors:
  - Andrew Parry
  - Catherine Chen
  - Carsten Eickhoff
  - Sean MacAvaney
links:
  Paper: https://arxiv.org/abs/2501.10165
  Code: https://github.com/Parry-Parry/MechIR
---
